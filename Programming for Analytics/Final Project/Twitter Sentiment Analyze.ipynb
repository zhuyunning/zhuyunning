{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwitterData(searchTerm):\n",
    "    \n",
    "    CONSUMER_KEY = 'mcHg73LXHcUtYfg6MYlTGvovU'\n",
    "    CONSUMER_SECRET = 'vieVDcxAFhFTltTnLUzoZRuwG6QryXFnFtItTqKerHYaWASumK'\n",
    "    OAUTH_TOKEN = '785603734495596544-OqeUxehteJnMqVw9MfYSDMPXcDatLmV'\n",
    "    OAUTH_TOKEN_SECRET = 'fGQ3162mmYMQHc9qo1rpZoLyyKfe4r77H0bnPegiFC1aY'\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #first get 300 twitters\n",
    "    tweets=[]\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchTerm).items(300):\n",
    "        tweets.append(tweet.text)\n",
    "    \n",
    "    #lower cases\n",
    "    lowered_texts = []\n",
    "    for texts in tweets:\n",
    "        try: \n",
    "            mytext = str(texts.lower())\n",
    "            lowered_texts.append(mytext)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #remove punctuations\n",
    "    punctuation = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    s_sans_punct = \"\"\n",
    "    for letter in str(lowered_texts):\n",
    "        if (letter not in punctuation) and (letter in \"abcdefghijklmnopqrstuvwxyz \"):\n",
    "            s_sans_punct += letter\n",
    "    \n",
    "    #get sentiment score using textblob\n",
    "    t=TextBlob(s_sans_punct)\n",
    "    sentiment=t.sentiment.polarity\n",
    "    sentiment_new=100*sentiment\n",
    "   \n",
    "    #text=[]\n",
    "    #text.append(s_sans_punct)\n",
    "    #title=[]\n",
    "    #title.append(searchTerm)\n",
    "    \n",
    "    #load data into dataframes and transform it into csv files\n",
    "    #df=pd.DataFrame()\n",
    "    #df['title']=title\n",
    "    #df['sentiment']=sentiment_new\n",
    "\n",
    "    return sentiment_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = getTwitterData('spy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = getTwitterData('The Martian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names=pd.read_csv('/home/hwu/Downloads/Top100MoviesNamesOnly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namelist = names.Name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(namelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mysenti=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sched, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for n in namelist:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    time.sleep(60)\n",
    "    mysenti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next10 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames12.csv')\n",
    "namelist10 = next10.Name.tolist()\n",
    "print(namelist10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in namelist10:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    time.sleep(30)\n",
    "    mysenti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/hwu/Downloads/senti.txt','a') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next20 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames21.csv')\n",
    "namelist20 = next20.Name.tolist()\n",
    "print(namelist20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in namelist20:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    time.sleep(10)\n",
    "    mysenti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/hwu/Downloads/senti_bkp_30.txt','a') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next30 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames31.csv')\n",
    "namelist30 = next30.Name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(namelist30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in namelist30:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    time.sleep(30)\n",
    "    mysenti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_bkp_40.txt','a') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mysenti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_bkp_40.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next40 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames41.csv')\n",
    "namelist40 = next40.Name.tolist()\n",
    "for n in namelist40:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_bkp_41.txt','a') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next42 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames42.csv')\n",
    "namelist42 = next42.Name.tolist()\n",
    "for n in namelist42:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "\n",
    "time.sleep(900)\n",
    "\n",
    "next50 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames51.csv')\n",
    "namelist50 = next50.Name.tolist()\n",
    "for n in namelist50:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwitterData2(searchTerm):\n",
    "    \n",
    "    CONSUMER_KEY = 'JzJnftI7E3dLpb5B5VpLKas4z'\n",
    "    CONSUMER_SECRET = '6PAevcl2Hlcw64mp30QDIyzV5aRirAvT4IlwUMAAJYD7kLsDLe'\n",
    "    OAUTH_TOKEN = '785603917631533056-evTF7SO4zs0CYLd2MihEbyw4bK0AgeT'\n",
    "    OAUTH_TOKEN_SECRET = 'UKnMkJo5yjo5qbw9Co33whQlA4Qt1ii7ZnaizYeHTnNRm'\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #first get 300 twitters\n",
    "    tweets=[]\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchTerm).items(300):\n",
    "        tweets.append(tweet.text)\n",
    "    \n",
    "    #lower cases\n",
    "    lowered_texts = []\n",
    "    for texts in tweets:\n",
    "        try: \n",
    "            mytext = str(texts.lower())\n",
    "            lowered_texts.append(mytext)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #remove punctuations\n",
    "    punctuation = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    s_sans_punct = \"\"\n",
    "    for letter in str(lowered_texts):\n",
    "        if (letter not in punctuation) and (letter in \"abcdefghijklmnopqrstuvwxyz \"):\n",
    "            s_sans_punct += letter\n",
    "    \n",
    "    #get sentiment score using textblob\n",
    "    t=TextBlob(s_sans_punct)\n",
    "    sentiment=t.sentiment.polarity\n",
    "    sentiment_new=100*sentiment\n",
    "   \n",
    "    #text=[]\n",
    "    #text.append(s_sans_punct)\n",
    "    #title=[]\n",
    "    #title.append(searchTerm)\n",
    "    \n",
    "    #load data into dataframes and transform it into csv files\n",
    "    #df=pd.DataFrame()\n",
    "    #df['title']=title\n",
    "    #df['sentiment']=sentiment_new\n",
    "\n",
    "    return sentiment_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_59.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next60 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames61.csv')\n",
    "namelist60 = next60.Name.tolist()\n",
    "for n in namelist60:\n",
    "    print(n)\n",
    "    score = getTwitterData2(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_joy.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next70 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames71.csv')\n",
    "namelist70 = next70.Name.tolist()\n",
    "for n in namelist70:\n",
    "    print(n)\n",
    "    score = getTwitterData2(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "\n",
    "time.sleep(900)\n",
    "next80 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames81.csv')\n",
    "namelist80 = next80.Name.tolist()\n",
    "for n in namelist80:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "\n",
    "time.sleep(900)\n",
    "next90 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames91.csv')\n",
    "namelist90 = next90.Name.tolist()\n",
    "for n in namelist90:\n",
    "    print(n)\n",
    "    score = getTwitterData2(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "    \n",
    "time.sleep(900)\n",
    "next100 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames100.csv')\n",
    "namelist100 = next100.Name.tolist()\n",
    "for n in namelist100:\n",
    "    print(n)\n",
    "    score = getTwitterData(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "    \n",
    "with open('/home/hwu/Downloads/senti_all.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hwu/Downloads/senti_97.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next101 = pd.read_csv('/home/hwu/Downloads/Top100MoviesNames101.csv')\n",
    "namelist101 = next101.Name.tolist()\n",
    "for n in namelist101:\n",
    "    print(n)\n",
    "    score = getTwitterData2(n)\n",
    "    print(score)\n",
    "    mysenti.append(score)\n",
    "    time.sleep(90)\n",
    "\n",
    "with open('/home/hwu/Downloads/senti_all.txt','w') as f:\n",
    "    wr = csv.writer(f, dialect='excel')\n",
    "    wr.writerow(mysenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames=glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Names':[],'Sentiment':[]})\n",
    "for x in filenames:\n",
    "    with open(x,'r') as f:\n",
    "        df.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
